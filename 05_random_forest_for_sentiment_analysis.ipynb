{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest for sentiment analysis\n",
    "\n",
    "In the previous chapter we saw one of the most promising models was based on Random Forest. It combines quite a good accuracy with a performance. It is really important if we'd like to move our model to production, so the best architecture, in terms of its precision, is not always a possible choice. \n",
    "\n",
    "We are going to begin with a simple description of the Random Forest, to understand how it works under the hood. In simple words, Random Forest is a collection of ensembled Decision Trees which vote in order to form a single decision of belonging to a particular class. Each Decision Tree uses a randomly selected subset of features in order to perform its own decision.\n",
    "\n",
    "## Tuning the model parameters\n",
    "\n",
    "Let's play a little bit with the hyperparameters of the Random Forest Classifier, to optimize its accuracy. First of all, let's list some of the possible parameters and their values: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "From our perspective the following parameters look like the ones we should test out:\n",
    "\n",
    "- **n_estimators** - number of decision trees used to make a forest, by default set to 10\n",
    "- **criterion** - quality function for measuring a split, can be set to \"gini\" (default) or \"entropy\"\n",
    "- **max_features** - a maximum number of features to consider (int - exact number, float - percentage, \"auto\", \"sqrt\", \"log2\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.24 s, sys: 568 ms, total: 5.81 s\n",
      "Wall time: 5.81 s\n",
      "Configuration: n_estimators = 5, criterion = gini, max_features = auto\n",
      "Train accuracy score: 0.9608948087431693\n",
      "Test accuracy score: 0.7209699453551912\n",
      "\n",
      "CPU times: user 2.56 s, sys: 524 ms, total: 3.08 s\n",
      "Wall time: 3.09 s\n",
      "Configuration: n_estimators = 5, criterion = gini, max_features = log2\n",
      "Train accuracy score: 0.9596994535519126\n",
      "Test accuracy score: 0.692964480874317\n",
      "\n",
      "CPU times: user 2min 46s, sys: 509 ms, total: 2min 47s\n",
      "Wall time: 2min 47s\n",
      "Configuration: n_estimators = 5, criterion = gini, max_features = None\n",
      "Train accuracy score: 0.9564549180327869\n",
      "Test accuracy score: 0.7182377049180327\n",
      "\n",
      "CPU times: user 5.81 s, sys: 704 ms, total: 6.52 s\n",
      "Wall time: 6.52 s\n",
      "Configuration: n_estimators = 5, criterion = entropy, max_features = auto\n",
      "Train accuracy score: 0.9627732240437158\n",
      "Test accuracy score: 0.7161885245901639\n",
      "\n",
      "CPU times: user 2.6 s, sys: 500 ms, total: 3.1 s\n",
      "Wall time: 3.1 s\n",
      "Configuration: n_estimators = 5, criterion = entropy, max_features = log2\n",
      "Train accuracy score: 0.9618340163934426\n",
      "Test accuracy score: 0.7069672131147541\n",
      "\n",
      "CPU times: user 1min 48s, sys: 600 ms, total: 1min 49s\n",
      "Wall time: 1min 49s\n",
      "Configuration: n_estimators = 5, criterion = entropy, max_features = None\n",
      "Train accuracy score: 0.9601263661202186\n",
      "Test accuracy score: 0.7298497267759563\n",
      "\n",
      "CPU times: user 9.13 s, sys: 516 ms, total: 9.65 s\n",
      "Wall time: 9.65 s\n",
      "Configuration: n_estimators = 10, criterion = gini, max_features = auto\n",
      "Train accuracy score: 0.9815573770491803\n",
      "Test accuracy score: 0.7308743169398907\n",
      "\n",
      "CPU times: user 4.99 s, sys: 448 ms, total: 5.44 s\n",
      "Wall time: 5.44 s\n",
      "Configuration: n_estimators = 10, criterion = gini, max_features = log2\n",
      "Train accuracy score: 0.9830088797814208\n",
      "Test accuracy score: 0.7288251366120219\n",
      "\n",
      "CPU times: user 5min 30s, sys: 639 ms, total: 5min 30s\n",
      "Wall time: 5min 31s\n",
      "Configuration: n_estimators = 10, criterion = gini, max_features = None\n",
      "Train accuracy score: 0.9770321038251366\n",
      "Test accuracy score: 0.7305327868852459\n",
      "\n",
      "CPU times: user 8.12 s, sys: 572 ms, total: 8.69 s\n",
      "Wall time: 8.69 s\n",
      "Configuration: n_estimators = 10, criterion = entropy, max_features = auto\n",
      "Train accuracy score: 0.9824965846994536\n",
      "Test accuracy score: 0.7435109289617486\n",
      "\n",
      "CPU times: user 4.55 s, sys: 508 ms, total: 5.06 s\n",
      "Wall time: 5.06 s\n",
      "Configuration: n_estimators = 10, criterion = entropy, max_features = log2\n",
      "Train accuracy score: 0.985228825136612\n",
      "Test accuracy score: 0.7325819672131147\n",
      "\n",
      "CPU times: user 3min 48s, sys: 630 ms, total: 3min 49s\n",
      "Wall time: 3min 50s\n",
      "Configuration: n_estimators = 10, criterion = entropy, max_features = None\n",
      "Train accuracy score: 0.976775956284153\n",
      "Test accuracy score: 0.742827868852459\n",
      "\n",
      "CPU times: user 21.4 s, sys: 596 ms, total: 22 s\n",
      "Wall time: 22 s\n",
      "Configuration: n_estimators = 25, criterion = gini, max_features = auto\n",
      "Train accuracy score: 0.9956454918032787\n",
      "Test accuracy score: 0.7459016393442623\n",
      "\n",
      "CPU times: user 10.7 s, sys: 500 ms, total: 11.2 s\n",
      "Wall time: 11.2 s\n",
      "Configuration: n_estimators = 25, criterion = gini, max_features = log2\n",
      "Train accuracy score: 0.9963285519125683\n",
      "Test accuracy score: 0.7472677595628415\n",
      "\n",
      "CPU times: user 14min 43s, sys: 653 ms, total: 14min 43s\n",
      "Wall time: 14min 44s\n",
      "Configuration: n_estimators = 25, criterion = gini, max_features = None\n",
      "Train accuracy score: 0.9938524590163934\n",
      "Test accuracy score: 0.7397540983606558\n",
      "\n",
      "CPU times: user 19.5 s, sys: 520 ms, total: 20 s\n",
      "Wall time: 20 s\n",
      "Configuration: n_estimators = 25, criterion = entropy, max_features = auto\n",
      "Train accuracy score: 0.9949624316939891\n",
      "Test accuracy score: 0.75\n",
      "\n",
      "CPU times: user 10.4 s, sys: 516 ms, total: 10.9 s\n",
      "Wall time: 10.9 s\n",
      "Configuration: n_estimators = 25, criterion = entropy, max_features = log2\n",
      "Train accuracy score: 0.9962431693989071\n",
      "Test accuracy score: 0.7476092896174863\n",
      "\n",
      "CPU times: user 8min 15s, sys: 528 ms, total: 8min 16s\n",
      "Wall time: 8min 16s\n",
      "Configuration: n_estimators = 25, criterion = entropy, max_features = None\n",
      "Train accuracy score: 0.9932547814207651\n",
      "Test accuracy score: 0.7455601092896175\n",
      "\n",
      "CPU times: user 37.9 s, sys: 484 ms, total: 38.4 s\n",
      "Wall time: 38.4 s\n",
      "Configuration: n_estimators = 50, criterion = gini, max_features = auto\n",
      "Train accuracy score: 0.9970969945355191\n",
      "Test accuracy score: 0.7534153005464481\n",
      "\n",
      "CPU times: user 19.9 s, sys: 488 ms, total: 20.4 s\n",
      "Wall time: 20.4 s\n",
      "Configuration: n_estimators = 50, criterion = gini, max_features = log2\n",
      "Train accuracy score: 0.9974385245901639\n",
      "Test accuracy score: 0.7544398907103825\n",
      "\n",
      "CPU times: user 32min 56s, sys: 877 ms, total: 32min 57s\n",
      "Wall time: 32min 58s\n",
      "Configuration: n_estimators = 50, criterion = gini, max_features = None\n",
      "Train accuracy score: 0.9964139344262295\n",
      "Test accuracy score: 0.7414617486338798\n",
      "\n",
      "CPU times: user 55.1 s, sys: 684 ms, total: 55.8 s\n",
      "Wall time: 55.8 s\n",
      "Configuration: n_estimators = 50, criterion = entropy, max_features = auto\n",
      "Train accuracy score: 0.9974385245901639\n",
      "Test accuracy score: 0.7575136612021858\n",
      "\n",
      "CPU times: user 25.3 s, sys: 644 ms, total: 25.9 s\n",
      "Wall time: 25.9 s\n",
      "Configuration: n_estimators = 50, criterion = entropy, max_features = log2\n",
      "Train accuracy score: 0.9975239071038251\n",
      "Test accuracy score: 0.7547814207650273\n",
      "\n",
      "CPU times: user 16min 51s, sys: 692 ms, total: 16min 52s\n",
      "Wall time: 16min 52s\n",
      "Configuration: n_estimators = 50, criterion = entropy, max_features = None\n",
      "Train accuracy score: 0.9968408469945356\n",
      "Test accuracy score: 0.7441939890710383\n",
      "\n",
      "CPU times: user 1min 13s, sys: 524 ms, total: 1min 13s\n",
      "Wall time: 1min 13s\n",
      "Configuration: n_estimators = 100, criterion = gini, max_features = auto\n",
      "Train accuracy score: 0.9976092896174863\n",
      "Test accuracy score: 0.762636612021858\n",
      "\n",
      "CPU times: user 38.3 s, sys: 536 ms, total: 38.9 s\n",
      "Wall time: 38.9 s\n",
      "Configuration: n_estimators = 100, criterion = gini, max_features = log2\n",
      "Train accuracy score: 0.9976092896174863\n",
      "Test accuracy score: 0.7599043715846995\n",
      "\n",
      "CPU times: user 55min 49s, sys: 692 ms, total: 55min 50s\n",
      "Wall time: 55min 51s\n",
      "Configuration: n_estimators = 100, criterion = gini, max_features = None\n",
      "Train accuracy score: 0.9975239071038251\n",
      "Test accuracy score: 0.7380464480874317\n",
      "\n",
      "CPU times: user 1min 14s, sys: 536 ms, total: 1min 14s\n",
      "Wall time: 1min 14s\n",
      "Configuration: n_estimators = 100, criterion = entropy, max_features = auto\n",
      "Train accuracy score: 0.9976092896174863\n",
      "Test accuracy score: 0.7609289617486339\n",
      "\n",
      "CPU times: user 39.6 s, sys: 520 ms, total: 40.1 s\n",
      "Wall time: 40.1 s\n",
      "Configuration: n_estimators = 100, criterion = entropy, max_features = log2\n",
      "Train accuracy score: 0.9976092896174863\n",
      "Test accuracy score: 0.7585382513661202\n",
      "\n",
      "CPU times: user 34min 35s, sys: 668 ms, total: 34min 36s\n",
      "Wall time: 34min 37s\n",
      "Configuration: n_estimators = 100, criterion = entropy, max_features = None\n",
      "Train accuracy score: 0.9976092896174863\n",
      "Test accuracy score: 0.7459016393442623\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run 02_data_preparation.ipynb\n",
    "\n",
    "import itertools\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "N_ESTIMATORS = (5, 10, 25, 50, 100)\n",
    "CRITERION = (\"gini\", \"entropy\")\n",
    "MAX_FEATURES = (\"auto\", \"log2\", None)\n",
    "\n",
    "# Divide the dataset into train and test fraction\n",
    "train_messages, test_messages, train_targets, test_targets = train_test_split(tweets[\"text\"], \n",
    "                                                                              tweets[\"sentiment\"],\n",
    "                                                                              test_size=0.2)\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "for n_estimators, criterion, max_features in itertools.product(N_ESTIMATORS,\n",
    "                                                               CRITERION,\n",
    "                                                               MAX_FEATURES):\n",
    "    # Define the classifier instance\n",
    "    classifier = RandomForestClassifier(random_state=2018, \n",
    "                                        n_estimators=n_estimators, \n",
    "                                        criterion=criterion, \n",
    "                                        max_features=max_features)\n",
    "    # Vectorize preprocessed sentences\n",
    "    train_features = vectorizer.fit_transform(train_messages)\n",
    "\n",
    "    # Train the model\n",
    "    %time fit = classifier.fit(train_features.toarray(), train_targets)\n",
    "\n",
    "    # Check the accuracy of the model on test data and display it\n",
    "    test_features = vectorizer.transform(test_messages)\n",
    "    train_predictions = fit.predict(train_features.toarray())\n",
    "    train_accuracy = accuracy_score(train_predictions, train_targets)\n",
    "    test_predictions = fit.predict(test_features.toarray())\n",
    "    test_accuracy = accuracy_score(test_predictions, test_targets)\n",
    "    print(\"Configuration: n_estimators = {}, criterion = {}, max_features = {}\\n\"\n",
    "          \"Train accuracy score: {}\\n\"\n",
    "          \"Test accuracy score: {}\\n\".format(n_estimators, criterion, max_features, \n",
    "                                             train_accuracy, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turned out the following configuration achieves the best accuracy on our test dataset:\n",
    "\n",
    "`n_estimators = 100, criterion = gini, max_features = auto`\n",
    "\n",
    "For that reason we are going to create a simple application that will use these parameters for training. That will be a console application reading the sentences from the user and classifies its sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise\n",
    "\n",
    "Please fill the gaps in the source code in *exercise/exercise_03.py*, in order to create an application that will:\n",
    "\n",
    "- create Random Forest based model and train it on a whole dataset used in previous examples, using selected parameters (`n_estimators = 100, criterion = gini, max_features = auto`)\n",
    "- continiously read the sentences from the standard input and classify them with the created model, until \"exit\" sentence is passed\n",
    "- display the probabilities of beloning to each class\n",
    "\n",
    "Some of the functionalities are already prepared - please complete the source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/exercise/exercise_03.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  tweets[\"text\"] = tweets[\"text\"].map(preprocess_text)\n",
      "/home/jovyan/exercise/exercise_03.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  tweets[\"sentiment\"] = tweets[\"sentiment\"].map(lambda x: SENTIMENT_TO_LABEL_MAPPING[x])\n"
     ]
    }
   ],
   "source": [
    "%run exercise/exercise_03.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
