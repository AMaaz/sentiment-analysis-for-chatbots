{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest for sentiment analysis\n",
    "\n",
    "In the previous chapter we saw one of the most promising models was based on Random Forest. It combines quite a good accuracy with a performance. It is really important if we'd like to move our model to production, so the best architecture, in terms of its precision, is not always a possible choice. \n",
    "\n",
    "We are goin to begin with a simple description of the Random Forest, to understand how it works under the hood. In simple words, Random Forest is a collection of ensembled Decision Trees which vote in order to form a single decision of belonging to a particular class. Each Decision Tree uses a randomly selected subset of features in order to make the decision.\n",
    "\n",
    "## Tuning the model parameters\n",
    "\n",
    "Let's play a little bit with the hyperparameters of the Random Forest Classifier, to optimize its accuracy. First of all, let's list some of the possible parameters and their values: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "From our perspective the following parameters look like the ones we should test out:\n",
    "\n",
    "- **n_estimators** - number of decision trees used to make a forest, by default set to 10\n",
    "- **criterion** - quality function for measuring a split, can be set to \"gini\" (default) or \"entropy\"\n",
    "- **max_features** - a maximum number of features to consider (int - exact number, float - percentage, \"auto\", \"sqrt\", \"log2\", None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.03 s, sys: 556 ms, total: 6.59 s\n",
      "Wall time: 6.59 s\n",
      "Configuration: n_estimators = 5, criterion = gini, max_features = auto\n",
      "Train accuracy score: 0.9596994535519126\n",
      "Test accuracy score: 0.6963797814207651\n",
      "\n",
      "CPU times: user 2.87 s, sys: 528 ms, total: 3.4 s\n",
      "Wall time: 3.4 s\n",
      "Configuration: n_estimators = 5, criterion = gini, max_features = log2\n",
      "Train accuracy score: 0.9631147540983607\n",
      "Test accuracy score: 0.6796448087431693\n",
      "\n",
      "CPU times: user 5min, sys: 745 ms, total: 5min\n",
      "Wall time: 5min 1s\n",
      "Configuration: n_estimators = 5, criterion = gini, max_features = None\n",
      "Train accuracy score: 0.9564549180327869\n",
      "Test accuracy score: 0.7110655737704918\n",
      "\n",
      "CPU times: user 5.25 s, sys: 564 ms, total: 5.82 s\n",
      "Wall time: 5.82 s\n",
      "Configuration: n_estimators = 5, criterion = entropy, max_features = auto\n",
      "Train accuracy score: 0.9605532786885246\n",
      "Test accuracy score: 0.6960382513661202\n",
      "\n",
      "CPU times: user 2.77 s, sys: 660 ms, total: 3.43 s\n",
      "Wall time: 3.43 s\n",
      "Configuration: n_estimators = 5, criterion = entropy, max_features = log2\n",
      "Train accuracy score: 0.961577868852459\n",
      "Test accuracy score: 0.6840846994535519\n",
      "\n",
      "CPU times: user 2min 25s, sys: 616 ms, total: 2min 25s\n",
      "Wall time: 2min 25s\n",
      "Configuration: n_estimators = 5, criterion = entropy, max_features = None\n",
      "Train accuracy score: 0.9569672131147541\n",
      "Test accuracy score: 0.7103825136612022\n",
      "\n",
      "CPU times: user 12 s, sys: 540 ms, total: 12.5 s\n",
      "Wall time: 12.5 s\n",
      "Configuration: n_estimators = 10, criterion = gini, max_features = auto\n",
      "Train accuracy score: 0.9799351092896175\n",
      "Test accuracy score: 0.7243852459016393\n",
      "\n",
      "CPU times: user 5.51 s, sys: 556 ms, total: 6.07 s\n",
      "Wall time: 6.07 s\n",
      "Configuration: n_estimators = 10, criterion = gini, max_features = log2\n",
      "Train accuracy score: 0.9842896174863388\n",
      "Test accuracy score: 0.7083333333333334\n",
      "\n",
      "CPU times: user 10min 28s, sys: 681 ms, total: 10min 28s\n",
      "Wall time: 10min 28s\n",
      "Configuration: n_estimators = 10, criterion = gini, max_features = None\n",
      "Train accuracy score: 0.975922131147541\n",
      "Test accuracy score: 0.7230191256830601\n",
      "\n",
      "CPU times: user 10.6 s, sys: 656 ms, total: 11.3 s\n",
      "Wall time: 11.3 s\n",
      "Configuration: n_estimators = 10, criterion = entropy, max_features = auto\n",
      "Train accuracy score: 0.9812158469945356\n",
      "Test accuracy score: 0.7206284153005464\n",
      "\n",
      "CPU times: user 5.49 s, sys: 508 ms, total: 6 s\n",
      "Wall time: 6 s\n",
      "Configuration: n_estimators = 10, criterion = entropy, max_features = log2\n",
      "Train accuracy score: 0.9836919398907104\n",
      "Test accuracy score: 0.7137978142076503\n",
      "\n",
      "CPU times: user 5min 26s, sys: 552 ms, total: 5min 26s\n",
      "Wall time: 5min 26s\n",
      "Configuration: n_estimators = 10, criterion = entropy, max_features = None\n",
      "Train accuracy score: 0.9786543715846995\n",
      "Test accuracy score: 0.7247267759562842\n",
      "\n",
      "CPU times: user 30.1 s, sys: 580 ms, total: 30.6 s\n",
      "Wall time: 30.6 s\n",
      "Configuration: n_estimators = 25, criterion = gini, max_features = auto\n",
      "Train accuracy score: 0.9962431693989071\n",
      "Test accuracy score: 0.7366803278688525\n",
      "\n",
      "CPU times: user 15 s, sys: 588 ms, total: 15.5 s\n",
      "Wall time: 15.5 s\n",
      "Configuration: n_estimators = 25, criterion = gini, max_features = log2\n",
      "Train accuracy score: 0.9969262295081968\n",
      "Test accuracy score: 0.7288251366120219\n",
      "\n",
      "CPU times: user 23min 23s, sys: 676 ms, total: 23min 23s\n",
      "Wall time: 23min 24s\n",
      "Configuration: n_estimators = 25, criterion = gini, max_features = None\n",
      "Train accuracy score: 0.994535519125683\n",
      "Test accuracy score: 0.7298497267759563\n",
      "\n",
      "CPU times: user 26 s, sys: 504 ms, total: 26.5 s\n",
      "Wall time: 26.5 s\n",
      "Configuration: n_estimators = 25, criterion = entropy, max_features = auto\n",
      "Train accuracy score: 0.9957308743169399\n",
      "Test accuracy score: 0.733948087431694\n",
      "\n",
      "CPU times: user 13.2 s, sys: 544 ms, total: 13.8 s\n",
      "Wall time: 13.8 s\n",
      "Configuration: n_estimators = 25, criterion = entropy, max_features = log2\n",
      "Train accuracy score: 0.9968408469945356\n",
      "Test accuracy score: 0.73224043715847\n",
      "\n",
      "CPU times: user 12min 21s, sys: 620 ms, total: 12min 22s\n",
      "Wall time: 12min 22s\n",
      "Configuration: n_estimators = 25, criterion = entropy, max_features = None\n",
      "Train accuracy score: 0.9944501366120219\n",
      "Test accuracy score: 0.7325819672131147\n",
      "\n",
      "CPU times: user 57 s, sys: 660 ms, total: 57.7 s\n",
      "Wall time: 57.7 s\n",
      "Configuration: n_estimators = 50, criterion = gini, max_features = auto\n",
      "Train accuracy score: 0.9976946721311475\n",
      "Test accuracy score: 0.7390710382513661\n",
      "\n",
      "CPU times: user 28.1 s, sys: 520 ms, total: 28.7 s\n",
      "Wall time: 28.7 s\n",
      "Configuration: n_estimators = 50, criterion = gini, max_features = log2\n",
      "Train accuracy score: 0.99786543715847\n",
      "Test accuracy score: 0.7407786885245902\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run 02_data_preparation.ipynb\n",
    "\n",
    "import itertools\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "N_ESTIMATORS = (5, 10, 25, 50, 100)\n",
    "CRITERION = (\"gini\", \"entropy\")\n",
    "MAX_FEATURES = (\"auto\", \"log2\", None)\n",
    "\n",
    "# Divide the dataset into train and test fraction\n",
    "train_messages, test_messages, train_targets, test_targets = train_test_split(tweets[\"text\"], \n",
    "                                                                              tweets[\"sentiment\"],\n",
    "                                                                              test_size=0.2)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "for n_estimators, criterion, max_features in itertools.product(N_ESTIMATORS,\n",
    "                                                               CRITERION,\n",
    "                                                               MAX_FEATURES):\n",
    "    # Define the classifier instance\n",
    "    classifier = RandomForestClassifier(random_state=2018, \n",
    "                                        n_estimators=n_estimators, \n",
    "                                        criterion=criterion, \n",
    "                                        max_features=max_features)\n",
    "    # Vectorize preprocessed sentences\n",
    "    train_features = vectorizer.fit_transform(train_messages)\n",
    "\n",
    "    # Train the model\n",
    "    %time fit = classifier.fit(train_features.toarray(), train_targets)\n",
    "\n",
    "    # Check the accuracy of the model on test data and display it\n",
    "    test_features = vectorizer.transform(test_messages)\n",
    "    train_predictions = fit.predict(train_features.toarray())\n",
    "    train_accuracy = accuracy_score(train_predictions, train_targets)\n",
    "    test_predictions = fit.predict(test_features.toarray())\n",
    "    test_accuracy = accuracy_score(test_predictions, test_targets)\n",
    "    print(\"Configuration: n_estimators = {}, criterion = {}, max_features = {}\\n\"\n",
    "          \"Train accuracy score: {}\\n\"\n",
    "          \"Test accuracy score: {}\\n\".format(n_estimators, criterion, max_features, \n",
    "                                             train_accuracy, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turned out the following configuration achieves the best accuracy on our test dataset:\n",
    "\n",
    "`n_estimators = 100, criterion = gini, max_features = auto`\n",
    "\n",
    "For that reason we are going to create a simple application that will use these parameters for training. That will be a console application reading the sentences from the user and classifies its sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise\n",
    "\n",
    "Please fill the gaps in the source code below, in order to create an application that will:\n",
    "\n",
    "- create Random Forest based model and train it on a whole dataset used in previous examples, using selected parameters\n",
    "- continiously read the sentences from the standard input and classify them with the created model, until \"exit\" sentence is passed\n",
    "- display the probabilities of beloning to each class\n",
    "\n",
    "Some of the functionalities are already prepared - please complete the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the dataset\n",
    "vectorizer = TfidfVectorizer()\n",
    "features = vectorizer.fit_transform(tweets[\"text\"])\n",
    "\n",
    "# Create the model an train it\n",
    "model = RandomForestClassifier(random_state=2018)\n",
    "fit_model = model.fit(features, tweets[\"sentiment\"])\n",
    "\n",
    "# Continiously read the sentences from the standard input\n",
    "# and classify them with the created model\n",
    "sentence = None\n",
    "while True:\n",
    "    sentence = input(\"Sentence ('exit' to close): \")\n",
    "    if sentence == \"exit\":\n",
    "        break\n",
    "    # Classify the message and display the probabilities\n",
    "    sentence_features = vectorizer.transform((sentence, ))\n",
    "    probabilities = fit_model.predict_proba(sentence_features)\n",
    "    print(\"Sentence: {}\\nProbabilities: {}\".format(sentence, \n",
    "                                                   zip(fit_model.classes_, probabilities[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
