{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis methods\n",
    "\n",
    "There is no ML method which solves specifically the problem of sentiment analysis, so it is important to test some different algorithms and choose the best one. In our tests we are going to use scikit-learn library, which is commonly used, especially for implementing POCs.\n",
    "\n",
    "The quality of the ML model has to be measured somehow in order to compare their efficiency for given problem. In our case we are going to use quite a simple metric, called accuracy. \n",
    "\n",
    "$$accuracy = \\frac{\\text{Number of correct predictions}}{\\text{Total number of predictions}}$$\n",
    "\n",
    "We have three different labels for our texts: positive, negative and neutral. To avoid dealing with texts, we are going to convert them to 1, -1 and 0, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 02_data_preparation.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with defining a base pipeline for our dataset. We're going to use some functions declared in previous parts of the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "SENTIMENT_TO_LABEL_MAPPING = {\n",
    "    \"negative\": -1,\n",
    "    \"neutral\": 0,\n",
    "    \"positive\": 1\n",
    "}\n",
    "\n",
    "# Load the dataset\n",
    "raw_tweets = pd.read_csv(\"data/twitter-airlines-sentiment.csv\")\n",
    "\n",
    "# Preprocess the data with the function declared previously\n",
    "tweets = raw_tweets[[\"airline_sentiment\", \"text\"]]\n",
    "tweets.columns = (\"sentiment\", \"text\", )\n",
    "tweets[\"text\"] = tweets[\"text\"].map(preprocess_text)\n",
    "tweets[\"sentiment\"] = tweets[\"sentiment\"].map(lambda x: SENTIMENT_TO_LABEL_MAPPING[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Divide the dataset into train and test fraction\n",
    "train_messages, test_messages, train_targets, test_targets = train_test_split(tweets[\"text\"], \n",
    "                                                                              tweets[\"sentiment\"],\n",
    "                                                                              test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.4 s, sys: 463 ms, total: 53.9 s\n",
      "Wall time: 53.9 s\n",
      "CPU times: user 57.8 ms, sys: 104 ms, total: 162 ms\n",
      "Wall time: 162 ms\n",
      "Vectorizer: CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)\n",
      "Classifier: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "Accuracy score:0.7042349726775956\n",
      "\n",
      "CPU times: user 10.1 s, sys: 396 ms, total: 10.5 s\n",
      "Wall time: 10.5 s\n",
      "CPU times: user 94.9 ms, sys: 100 ms, total: 195 ms\n",
      "Wall time: 194 ms\n",
      "Vectorizer: CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)\n",
      "Classifier: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=2018,\n",
      "            verbose=0, warm_start=False)\n",
      "Accuracy score:0.7359972677595629\n",
      "\n",
      "CPU times: user 1min 18s, sys: 488 ms, total: 1min 18s\n",
      "Wall time: 1min 18s\n",
      "CPU times: user 85.3 ms, sys: 124 ms, total: 209 ms\n",
      "Wall time: 209 ms\n",
      "Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "Classifier: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "Accuracy score:0.6806693989071039\n",
      "\n",
      "CPU times: user 11.7 s, sys: 556 ms, total: 12.3 s\n",
      "Wall time: 12.3 s\n",
      "CPU times: user 117 ms, sys: 148 ms, total: 265 ms\n",
      "Wall time: 264 ms\n",
      "Vectorizer: TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "Classifier: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=2018,\n",
      "            verbose=0, warm_start=False)\n",
      "Accuracy score:0.7394125683060109\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Declare vectorizers to be used\n",
    "VECTORIZERS = (\n",
    "    CountVectorizer(),\n",
    "    TfidfVectorizer(),\n",
    ")\n",
    "\n",
    "# Declare classifiers to be used\n",
    "CLASSIFIERS = (\n",
    "#     LogisticRegression(C=10e-5, solver=\"liblinear\", max_iter=10000),\n",
    "#     KNeighborsClassifier(9),\n",
    "#     SVC(kernel=\"rbf\", C=0.025, probability=True),\n",
    "#     LinearSVC(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(random_state=2018),\n",
    "#     GaussianNB(),\n",
    ")\n",
    "\n",
    "for vectorizer, classifier in itertools.product(VECTORIZERS, CLASSIFIERS):\n",
    "    # Vectorize preprocessed sentences\n",
    "    train_features = vectorizer.fit_transform(train_messages)\n",
    "\n",
    "    # Train the model\n",
    "    %time fit = classifier.fit(train_features.toarray(), train_targets)\n",
    "\n",
    "    # Check the accuracy of the model on test data and display it\n",
    "    test_features = vectorizer.transform(test_messages)\n",
    "    %time test_predictions = fit.predict(test_features.toarray())\n",
    "    accuracy = accuracy_score(test_predictions, test_targets)\n",
    "    print(\"Vectorizer: {}\\nClassifier: {}\\nAccuracy score:{}\\n\".format(vectorizer,\n",
    "                                                                       classifier, \n",
    "                                                                       accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
